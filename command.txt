python -m venv .venv

.venv\Scripts\activate

pip uninstall -y torch torchvision torchaudio vllm

pip install --index-url https://download.pytorch.org/whl/cpu torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1

pip install transformers==4.47.0 datasets==3.1.0 accelerate==1.2.1 peft==0.14.0 sentencepiece==0.2.0 sympy antlr4-python3-runtime pebble

pip install -U llamafactory

pip install hf_transfer

pip install matplotlib
pip install seaborn

python -m pip install "lm-eval>=0.4.2"

python -c "import torch, torchvision, torchaudio; print('torch', torch.__version__); print('torchvision', torchvision.__version__); print('torchaudio', torchaudio.__version__)"

python patch_eval_cpu_safe.py 

python patch_enforce_compression.py

$env:HF_HUB_ENABLE_HF_TRANSFER = "1"

$env:TRANSFORMERS_NO_TORCHVISION=1
$env:OMP_NUM_THREADS=4                                                                      
$env:MKL_NUM_THREADS=4

Baseline (Full CoT):
python .\evaluation.py `
  --model-path "Qwen/Qwen2.5-0.5B-Instruct" `
  --tokenizer-path "Qwen/Qwen2.5-0.5B-Instruct" `
  --model-type qwen `
  --benchmark gsm8k `
  --data-type test `
  --max_num_examples 50 `
  --max_new_tokens 192 `
  --temperature 0.0 `
  --eval_batch_size 2 `
  --output-dir "outputs/Qwen2.5-0.5B-Instruct/full_cot/" `
  --seed 42


Compressed CoT (example ratio = 0.60):
python .\evaluation.py `
  --model-path "Qwen/Qwen2.5-0.5B-Instruct" `
  --tokenizer-path "Qwen/Qwen2.5-0.5B-Instruct" `
  --model-type qwen `
  --benchmark gsm8k `
  --data-type test `
  --max_num_examples 50 `
  --max_new_tokens 192 `
  --compression_ratio 0.60 `
  --temperature 0.0 `
  --eval_batch_size 2 `
  --output-dir "outputs/Qwen2.5-0.5B-Instruct/compressed_cot/" `
  --seed 42

python validate_side_by_side.py

python instrument_run.py --run-dir "outputs/Qwen2.5-0.5B-Instruct/full_cot/7b/Original/test/samples" --out-csv full_cot_samples.csv
python instrument_run.py --run-dir "outputs/Qwen2.5-0.5B-Instruct/compressed_cot/7b/Original/test/samples" --out-csv compressed_cot_samples.csv

python .\compare_metrics.py `
  "outputs/Qwen2.5-0.5B-Instruct/full_cot/" `
  "outputs/Qwen2.5-0.5B-Instruct/compressed_cot/"

deactivate

$env:CUDA_VISIBLE_DEVICES = ""

llamafactory-cli train `
  --model_name_or_path "Qwen/Qwen2.5-0.5B-Instruct" `
  --stage sft `
  --finetuning_type lora `
  --dataset gsm8k_cot60 `
  --dataset_dir data `
  --template qwen `
  --output_dir "lora_out/qwen25-0.5b-cot60-lora" `
  --cutoff_len 1024 `
  --per_device_train_batch_size 1 `
  --gradient_accumulation_steps 32 `
  --learning_rate 2e-4 `
  --num_train_epochs 1 `
  --lora_rank 8 `
  --lora_alpha 16 `
  --lora_dropout 0.05 `
  --fp16 false `
  --bf16 false `
  --overwrite_cache true `
  --low_cpu_mem_usage true `
  --offload_folder "offload_cpu" `
  --gradient_checkpointing true `
  --optim adamw_torch `
  --use_cpu true
